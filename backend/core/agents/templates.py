# Copyright (c) 2025 Cade Russell (Ghost Peony)
#
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.

"""
Agent Template Library for LangConfig.
Enhanced with Resilience, Optimization, and HITL capabilities.

This provides a BANK of reusable agent presets that users can add to their blueprints.
Each template defines a complete agent configuration including:
- Model selection with fallback models for resilience
- Tools (MCP)
- Enhancement flags
- System prompts
- Behavior settings
- HITL flags for safety-critical operations

Users can:
1. Browse template library in UI
2. Drag-and-drop templates into their blueprints
3. Customize after adding
4. Save their own custom templates
"""

from typing import Dict, List, Any, Optional, Sequence
from enum import Enum
# Use langchain_core.pydantic_v1 for better compatibility within the LangChain ecosystem
from pydantic import BaseModel, Field


class AgentCategory(str, Enum):
    """Categories of agent templates."""
    CODE_GENERATION = "code_generation"
    CODE_REVIEW = "code_review"
    TESTING = "testing"
    DEVOPS = "devops"
    RESEARCH = "research"
    ARCHITECTURE = "architecture"
    DOCUMENTATION = "documentation"
    PLANNING = "planning"
    QA_VALIDATION = "qa_validation"
    CONTENT_GENERATION = "content_generation"  # Visual content, images, media


class AgentTemplate(BaseModel):
    """
    Reusable and optimized agent configuration template.

    Example Usage:
        >>> template = AgentTemplateRegistry.get("code_implementer")
        >>> agent_config = template.to_agent_config()
        >>> agent = await AgentFactory.create_agent(
        ...     agent_config=agent_config,
        ...     project_id=1,
        ...     task_id=42,
        ...     context=context_package
        ... )
    """
    template_id: str = Field(..., description="Unique template identifier")
    name: str = Field(..., description="Display name")
    description: str = Field(..., description="Quick summary of what this agent does and when to use it.")
    category: AgentCategory

    # ðŸ·ï¸ LIGHTWEIGHT METADATA (For search/filtering/UI)
    capabilities: List[str] = Field(
        default_factory=list,
        description="Brief capability tags for search and filtering"
    )

    # Detailed docs live in /docs/agents/{template_id}.md

    # Model Configuration (Enhanced for Resilience - Chapter 12/16)
    model: str = Field(default="gpt-4o", description="Primary model")
    fallback_models: Sequence[str] = Field(
        default_factory=list,
        description="Models to use if the primary fails (e.g., rate limits, errors)."
    )
    temperature: float = Field(default=0.5, ge=0.0, le=2.0)
    max_tokens: Optional[int] = None

    # System Prompt (Focus on Role/Goal; AgentFactory injects Reasoning Framework)
    system_prompt: str = Field(..., description="Agent's role, expertise, constraints, and goals.")

    # MCP Tools
    mcp_tools: List[str] = Field(
        default_factory=list,
        description="List of MCP tool categories required (e.g., ['filesystem', 'git'])"
    )

    # CLI Tools
    cli_tools: List[str] = Field(
        default_factory=list,
        description="List of CLI tool categories (e.g., ['jira']). These are native LangChain tools."
    )

    # Custom Tools
    custom_tools: List[str] = Field(
        default_factory=list,
        description="List of custom tool IDs created by user (e.g., ['slack_notifier', 'image_generator'])"
    )

    # âœ¨ Enhancement Flags
    enable_model_routing: bool = Field(
        default=True,
        description="Auto-select optimal model based on task complexity (40-60% cost savings)"
    )
    enable_parallel_tools: bool = Field(
        default=True,
        description="Execute multiple tools concurrently (3-5x speedup)"
    )
    enable_memory: bool = Field(
        default=False,
        description="Enable long-term memory tools (VectorDB based) for learning and consistency."
    )
    memory_types: List[str] = Field(
        default_factory=lambda: ["fact", "decision", "pattern"],
        description="Types of memories to track"
    )
    enable_rag: bool = Field(
        default=False,
        description="Enable RAG (codebase search) tools for retrieving embedded codebase knowledge."
    )

    # Model Hooks (DEPRECATED: Use middleware instead)
    model_hooks: List[Dict[str, Any]] = Field(
        default_factory=list,
        description="Model hooks for context injection, validation, logging. List of hook configs. DEPRECATED - use middleware instead."
    )
    enable_default_hooks: bool = Field(
        default=True,
        description="Enable default hooks (timestamp, project context, logging). DEPRECATED - use middleware instead."
    )

    # Middleware (LangChain 1.1: Now supports ModelRetryMiddleware, ModelFallbackMiddleware, SummarizationMiddleware, etc.)
    middleware: List[Dict[str, Any]] = Field(
        default_factory=list,
        description="LangChain 1.1 middleware pipeline. Supports: retry, fallback, summarization, moderation, etc."
    )

    # Structured Outputs (LangChain 1.1: ProviderStrategy for auto-detection)
    output_schema_name: Optional[str] = Field(
        None,
        description="Name of structured output schema to use (e.g., 'code_review', 'sql_query')"
    )
    enable_structured_output: bool = Field(
        default=False,
        description="Enable type-safe Pydantic output schemas"
    )
    output_strategy: str = Field(
        default="auto",
        description="LangChain 1.1 ProviderStrategy: 'auto' (detect from model profile), 'native' (JSON mode), 'tool_calling'"
    )
    strict_schema: bool = Field(
        default=True,
        description="LangChain 1.1: Enable strict structured output mode (OpenAI strict mode)"
    )

    # Prompt Caching (LangChain 1.1: SystemMessage cache_control)
    enable_prompt_caching: bool = Field(
        default=False,
        description="LangChain 1.1: Enable prompt caching via SystemMessage cache_control (Anthropic/OpenAI)"
    )

    # Guardrails (Chapter 13/18 - Safety & HITL)
    requires_human_approval: bool = Field(
        default=False,
        description="Flag critical tasks requiring Human-in-the-Loop (HITL) before execution."
    )

    # Additional Settings
    timeout_seconds: int = Field(default=600)
    max_retries: int = Field(default=3)  # Used by ModelRetryMiddleware in 1.1
    retry_backoff_factor: float = Field(
        default=2.0,
        description="LangChain 1.1: Backoff factor for ModelRetryMiddleware exponential backoff"
    )
    enable_context: bool = Field(default=True)
    context_limit: int = Field(default=5)

    # Metadata
    tags: List[str] = Field(default_factory=list)
    version: str = Field(default="2.0.0")
    author: Optional[str] = None
    is_public: bool = Field(default=True)

    def to_agent_config(self) -> Dict[str, Any]:
        """
        Convert template to agent_config dict for blueprint/AgentFactory.

        This is what gets saved in the blueprint node's agent_config field.
        """
        return {
            "model": self.model,
            "fallback_models": self.fallback_models,  # NEW: Resilience
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "system_prompt": self.system_prompt,
            "mcp_tools": self.mcp_tools,
            "cli_tools": self.cli_tools,  # NEW: CLI Tools
            "custom_tools": self.custom_tools,  # NEW: Custom user-defined tools
            "enable_model_routing": self.enable_model_routing,
            "enable_parallel_tools": self.enable_parallel_tools,
            "enable_memory": self.enable_memory,
            "memory_types": self.memory_types,
            "enable_rag": self.enable_rag,
            "model_hooks": self.model_hooks,  # DEPRECATED: Use middleware
            "enable_default_hooks": self.enable_default_hooks,  # DEPRECATED: Use middleware
            "middleware": self.middleware,  # LangChain 1.1 middleware pipeline
            "output_schema_name": self.output_schema_name,
            "enable_structured_output": self.enable_structured_output,
            # LangChain 1.1: ProviderStrategy and strict mode
            "output_strategy": self.output_strategy,
            "strict_schema": self.strict_schema,
            # LangChain 1.1: Prompt caching
            "enable_prompt_caching": self.enable_prompt_caching,
            "requires_human_approval": self.requires_human_approval,  # HITL
            "timeout_seconds": self.timeout_seconds,
            "max_retries": self.max_retries,
            "retry_backoff_factor": self.retry_backoff_factor,  # LangChain 1.1
            "enable_context": self.enable_context,
            "context_limit": self.context_limit,
            # Metadata
            "template_id": self.template_id,
            "template_version": self.version
        }


# =============================================================================
# AGENT TEMPLATE LIBRARY - Optimized Presets
# =============================================================================

# ---- ARCHITECTURE & DESIGN ----

ARCHITECT_AGENT = AgentTemplate(
    template_id="system_architect",
    name="System Architect",
    description="Designs scalable system architectures, data models, and API specifications with trade-off analysis.",
    category=AgentCategory.ARCHITECTURE,

    capabilities=[
        "system-design", "microservices", "data-modeling", "api-design",
        "security-architecture", "scalability", "cloud-architecture", "mermaid-diagrams"
    ],

    model="claude-sonnet-4-5-20250929",
    fallback_models=["gpt-5", "gemini-2.5-pro"],
    temperature=0.3,
    system_prompt="""ROLE: Senior Software Architect.
EXPERTISE: Scalable system design, data modeling, API specification (OpenAPI), security best practices.
GOAL: Analyze requirements and context to design a robust architecture. Define clear data models and API contracts.
CONSTRAINTS: Prioritize maintainability. Document trade-offs. Align with existing infrastructure. Use memory tools (Type: DECISION) to record key choices.
OUTPUT: Architectural diagrams (Mermaid), detailed schemas, and OpenAPI specifications.""",

    mcp_tools=["file_read", "file_write", "file_list", "web_search", "reasoning_chain"],  # Added web for research, sequential_thinking for complex reasoning

    enable_model_routing=False,
    enable_parallel_tools=False,
    enable_memory=True,
    memory_types=["decision", "pattern", "relationship"],
    tags=["architecture", "design", "planning", "expert"]
)

# ---- CODE GENERATION ----

CODE_IMPLEMENTER = AgentTemplate(
    template_id="code_implementer",
    name="Code Implementer (General)",
    description="Writes clean, functional code based on specifications. Best for feature implementation and bug fixes.",
    category=AgentCategory.CODE_GENERATION,

    capabilities=[
        "full-stack", "multi-language", "git-workflow", "testing",
        "api-development", "database", "error-handling"
    ],

    model="gpt-5",
    fallback_models=["claude-sonnet-4-5-20250929", "gpt-4o"],
    temperature=0.5,
    system_prompt="""ROLE: Software Engineer.
EXPERTISE: Full-stack development, clean code principles (SOLID, DRY).
GOAL: Implement requested features or bug fixes efficiently and accurately based on specifications.
CONSTRAINTS: Adhere strictly to existing code style. Write modular, testable code. Handle errors gracefully.
OUTPUT: Clean, functional code that meets specifications and follows best practices.""",

    mcp_tools=["file_read", "file_write", "file_list", "web_search", "reasoning_chain"],  # Added web (docs lookup), sequential_thinking (complex logic)

    enable_model_routing=True,
    enable_parallel_tools=True,
    enable_memory=True,
    memory_types=["pattern", "learning", "fact"],
    tags=["code-generation", "implementation", "bug-fix"]
)

FAST_IMPLEMENTER = AgentTemplate(
    template_id="fast_implementer",
    name="Fast Code Implementer",
    description="Optimized for speed. Best for simple, well-defined tasks.",
    category=AgentCategory.CODE_GENERATION,

    capabilities=["simple-crud", "quick-fixes", "boilerplate", "copy-modify", "speed-optimized"],

    model="gpt-4o-mini",
    fallback_models=["claude-3-5-haiku-20241022", "gemini-2.0-flash"],
    temperature=0.6,
    system_prompt="""ROLE: Junior Software Engineer (Efficient Executor).
EXPERTISE: Rapid implementation of well-defined tasks.
GOAL: Complete straightforward coding tasks quickly and accurately.
CONSTRAINTS: Follow existing patterns. Minimal overthinking. Ask for clarification only if absolutely necessary.
OUTPUT: Quick, functional implementations that follow existing code patterns.""",

    mcp_tools=["file_read", "file_write", "file_list"],  # Keep minimal for speed

    enable_model_routing=True,
    enable_parallel_tools=True,
    enable_memory=False,
    tags=["code-generation", "fast", "simple", "cost-effective"]
)

REFACTOR_SPECIALIST = AgentTemplate(
    template_id="refactor_specialist",
    name="Refactoring Specialist",
    description="Code refactoring and cleanup. Improves code quality without changing behavior.",
    category=AgentCategory.CODE_GENERATION,

    capabilities=["refactoring", "design-patterns", "solid-principles", "code-smells", "test-preservation"],

    model="claude-sonnet-4-5-20250929",
    fallback_models=["gpt-5"],
    temperature=0.3,
    system_prompt="""ROLE: Refactoring Expert.
EXPERTISE: Code quality improvement, design patterns, SOLID principles.
GOAL: Improve code structure and maintainability without changing behavior.
CONSTRAINTS: Preserve existing behavior (no breaking changes). Maintain test coverage. Extract reusable components. Apply design patterns appropriately.
OUTPUT: Clean, well-structured code with improved readability and maintainability.""",

    mcp_tools=["file_read", "file_write", "file_list", "reasoning_chain"],  # Added sequential_thinking for refactoring planning

    enable_model_routing=True,
    enable_parallel_tools=True,
    enable_memory=True,
    memory_types=["pattern", "learning"],
    tags=["refactoring", "code-quality", "maintenance"]
)

# ---- CODE REVIEW ----

CODE_REVIEWER = AgentTemplate(
    template_id="code_reviewer",
    name="Code Reviewer",
    description="Thorough code review for quality, security, and best practices. Uses real verification tools (tests, linters) for rigorous validation. Provides structured output with categorized issues.",
    category=AgentCategory.CODE_REVIEW,

    capabilities=["code-review", "security-analysis", "best-practices", "pr-comments", "test-execution", "static-analysis"],

    model="claude-sonnet-4-5-20250929",  # Claude 4.5 Sonnet - Excellent at code analysis
    fallback_models=["gpt-5"],
    temperature=0.2,  # Low temperature for consistent reviews
    output_schema_name="code_review",  # NEW: Structured output with CodeReviewOutput schema
    enable_structured_output=True,  # NEW: Type-safe code review responses
    system_prompt="""ROLE: Senior Code Reviewer.
EXPERTISE: Code quality analysis, security vulnerabilities, performance optimization, best practices.
GOAL: Provide thorough, evidence-based code review with actionable feedback.

REVIEW WORKFLOW:
1. MANUAL REVIEW: Analyze code changes for logic, security, best practices
2. IDENTIFY ISSUES: Categorize by severity (Critical/Important/Nice-to-Have)
3. PROVIDE FEEDBACK: Give specific, actionable recommendations with code examples
4. DECISION MARKER: End your response with:
   - [DECISION: PASS] if code meets quality standards
   - [DECISION: FAIL_RETRY] if fixable issues found (provide specific feedback)
   - [DECISION: HITL_REQUIRED] if critical/ambiguous issues require human judgment

TOOLS AVAILABLE:
- file_read, file_write, file_list: For reviewing code files
- web_search: Look up security best practices, framework documentation
- reasoning_chain: Structure complex code analysis

CONSTRAINTS: Be thorough but concise. Prioritize critical issues. Focus on security, maintainability, and correctness.
OUTPUT: Categorized feedback with specific code examples and clear recommendations.""",
    mcp_tools=["file_read", "file_write", "file_list", "web_search", "reasoning_chain"],  # Only valid tools
    enable_model_routing=True,
    enable_parallel_tools=True,  # Can run tests and linters in parallel
    enable_memory=True,  # Remember past issues and patterns
    memory_types=["learning", "pattern"],
    tags=["code-review", "quality", "security", "verification", "critic"]
)

# ---- TESTING ----

TEST_GENERATOR = AgentTemplate(
    template_id="test_generator",
    name="Test Generator",
    description="Creates comprehensive test suites (unit, integration, e2e).",
    category=AgentCategory.TESTING,

    capabilities=["unit-testing", "integration-testing", "test-coverage", "tdd"],

    model="gpt-5",  # GPT-5 - Excellent at writing tests
    fallback_models=["claude-sonnet-4-5-20250929"],
    temperature=0.4,
    system_prompt="""ROLE: QA Engineer & Test Automation Specialist.
EXPERTISE: Unit testing, integration testing, test-driven development, Jest/Pytest/etc.
GOAL: Generate comprehensive, maintainable test suites covering edge cases.
CONSTRAINTS: Follow existing test conventions. Ensure tests are isolated and deterministic. Aim for >80% coverage.
OUTPUT: Well-structured test files with clear descriptions, comprehensive coverage, and good test data.""",
    mcp_tools=["file_read", "file_write", "file_list", "web_search", "reasoning_chain"],  # Added web (testing framework docs), sequential_thinking (comprehensive coverage planning)
    enable_model_routing=True,
    enable_parallel_tools=True,
    enable_memory=True,  # Remember testing patterns
    memory_types=["pattern", "fact"],
    tags=["testing", "qa", "tdd", "automation"]
)

QA_VALIDATOR = AgentTemplate(
    template_id="qa_validator",
    name="QA Validator",
    description="Validates code quality through automated checks. Fast and cost-effective.",
    category=AgentCategory.QA_VALIDATION,

    capabilities=["automated-testing", "quality-gates", "linting", "ci-cd-validation"],

    model="gemini-2.0-flash",  # Fast and efficient for validation tasks
    fallback_models=["gpt-4o-mini"],
    temperature=0.3,
    system_prompt="""ROLE: QA Validator (Automated Checks).
EXPERTISE: Test execution, linting, type checking, quality gates.
GOAL: Run automated quality checks and report issues clearly.
CONSTRAINTS: Be fast and thorough. Report actionable feedback. Focus on blocking issues.
OUTPUT: Clear validation report with pass/fail status and actionable items.""",
    mcp_tools=["browser"],  # Added for visual regression testing
    enable_model_routing=True,  # Will use even cheaper models
    enable_parallel_tools=True,  # Run checks concurrently
    enable_memory=False,
    tags=["qa", "validation", "testing", "automated"]
)

# ---- DEVOPS (HITL Example) ----

DEVOPS_AGENT = AgentTemplate(
    template_id="devops_automation",
    name="DevOps Agent (HITL Required)",
    description="Infrastructure and deployment tasks. Requires human approval for execution.",
    category=AgentCategory.DEVOPS,

    capabilities=["ci-cd", "docker", "kubernetes", "terraform", "infrastructure-as-code"],

    model="gpt-5",  # GPT-5 for infrastructure tasks
    fallback_models=["claude-sonnet-4-5-20250929"],
    temperature=0.2,  # Low temperature for safety
    system_prompt="""ROLE: DevOps Expert (Restricted).
EXPERTISE: CI/CD, Docker, Kubernetes, Terraform, Cloud Infrastructure.
GOAL: Plan and prepare infrastructure changes or deployment scripts.
CONSTRAINTS: SAFETY FIRST. You MUST generate the plan and required commands, but DO NOT execute them directly. A human operator will review and approve the generated plan. Define clear rollback procedures.""",
    mcp_tools=["file_read", "file_write", "file_list", "web_search", "reasoning_chain"],  # Added web (cloud docs), sequential_thinking (deployment planning)
    enable_model_routing=False,  # Use consistent powerful model
    enable_parallel_tools=False,  # DevOps must be sequential
    enable_memory=True,  # Remember infrastructure decisions
    memory_types=["decision", "fact", "learning"],
    requires_human_approval=True,  # HITL Guardrail enforced
    tags=["devops", "infrastructure", "deployment", "HITL", "safety-critical"]
)

# ---- RESEARCH ----

RESEARCH_AGENT = AgentTemplate(
    template_id="research_agent",
    name="Research & Analysis Agent",
    description="Researches technical topics, analyzes codebases, provides recommendations.",
    category=AgentCategory.RESEARCH,

    capabilities=["code-analysis", "technology-research", "architecture-review", "best-practices"],

    model="gemini-2.5-pro",  # Large context window, excellent for research
    fallback_models=["claude-sonnet-4-5-20250929", "gpt-5"],
    temperature=0.4,
    system_prompt="""ROLE: Technical Research Analyst.
EXPERTISE: Code analysis, architecture review, technology evaluation, best practices research.
GOAL: Thoroughly investigate and provide well-reasoned recommendations.
CONSTRAINTS: Cite sources when applicable. Consider trade-offs. Provide actionable insights.
OUTPUT: Structured analysis with clear recommendations and rationale.""",
    mcp_tools=["file_read", "file_write", "file_list", "web_search", "browser", "reasoning_chain"],  # Added web (docs/APIs), browser (dynamic content scraping), sequential_thinking (systematic research)
    enable_model_routing=False,  # Use powerful model for deep analysis
    enable_parallel_tools=True,  # Search multiple sources
    enable_memory=True,  # Remember research findings
    memory_types=["fact", "decision", "relationship"],
    tags=["research", "analysis", "investigation"]
)

# ---- DOCUMENTATION ----

DOCUMENTATION_WRITER = AgentTemplate(
    template_id="doc_writer",
    name="Documentation Writer",
    description="Creates clear, comprehensive documentation (README, API docs, tutorials). Provides structured output with sections and examples.",
    category=AgentCategory.DOCUMENTATION,

    capabilities=["technical-writing", "api-docs", "tutorials", "markdown", "code-examples"],

    model="gpt-4o-mini",  # Cost-effective for documentation
    fallback_models=["claude-3-5-haiku-20241022"],
    temperature=0.6,
    output_schema_name="documentation",  # NEW: Structured output with DocumentationOutput schema
    enable_structured_output=True,  # NEW: Type-safe documentation responses
    system_prompt="""ROLE: Technical Writer.
EXPERTISE: Clear technical communication, API documentation, user guides, Markdown/MDX.
GOAL: Create documentation that is clear, concise, and helpful for the target audience.
CONSTRAINTS: Use examples liberally. Structure content logically. Maintain consistent tone. Keep it scannable.
OUTPUT: Well-formatted Markdown documents with code examples and diagrams where appropriate.""",
    mcp_tools=["file_read", "file_write", "file_list", "web_search", "browser"],  # Added web (documentation best practices), browser (capture screenshots for docs)
    enable_model_routing=True,  # Docs can use cheap models
    enable_parallel_tools=False,
    enable_memory=False,
    tags=["documentation", "writing", "communication"]
)

# ---- PLANNING ----

TASK_PLANNER = AgentTemplate(
    template_id="task_planner",
    name="Task Planner (MCGS)",
    description="Strategic task planning with MCGS approach exploration. Explores 2-3 alternative approaches before selecting the best one. Provides structured output with full task breakdown.",
    category=AgentCategory.PLANNING,

    capabilities=["task-decomposition", "mcgs-planning", "dependency-analysis", "estimation", "milestone-planning", "approach-comparison"],

    model="gpt-5",  # GPT-5 for strategic planning
    fallback_models=["claude-sonnet-4-5-20250929"],
    temperature=0.3,
    output_schema_name="task_plan",  # Structured output with TaskPlanOutput schema (includes MCGS)
    enable_structured_output=True,  # Type-safe task planning responses
    system_prompt="""ROLE: Strategic Planning Specialist with MCGS (Monte Carlo Graph Search).
EXPERTISE: Task decomposition, approach exploration, dependency analysis, effort estimation, risk assessment.

CRITICAL REQUIREMENT - MCGS APPROACH EXPLORATION:
For complex tasks (features, refactors, architecture), you MUST explore 2-3 alternative approaches before selecting one.
This improves decision quality and ensures the best path forward.

WORKFLOW:
1. **Understand the Goal**: Analyze the task requirements and constraints
2. **Explore Approaches** (MCGS): Generate 2-3 alternative approaches:
   - Approach A: [Brief name]
     - Description: How it works
     - Pros: Advantages
     - Cons: Disadvantages & risks
     - Confidence: 0.0-1.0
     - Complexity: simple/moderate/complex
   - Approach B: [Alternative approach]
   - Approach C: [Optional third approach]
3. **Select Best Approach**: Choose the optimal approach based on:
   - Project context and constraints
   - Team capabilities
   - Time/resource availability
   - Risk profile
   - Long-term maintainability
4. **Detailed Plan**: Break down the selected approach into actionable steps with:
   - Clear dependencies
   - Realistic time estimates
   - Success criteria for each step
   - Required tools and resources

CONSTRAINTS:
- For simple tasks (< 30 min), you may skip MCGS and provide a direct plan
- For complex tasks, MCGS is MANDATORY - always explore alternatives
- Be realistic about effort estimates
- Identify risks early
- Ensure all subtasks are actionable

OUTPUT FORMAT:
Use the structured TaskPlanOutput schema which includes:
- Task classification
- Approaches explored (MCGS)
- Selected approach with rationale
- Detailed step-by-step plan
- Risk assessment
- Success metrics
- Confidence score""",
    mcp_tools=["reasoning_chain"],  # CRITICAL - essential for MCGS reasoning and planning
    enable_model_routing=True,
    enable_parallel_tools=False,  # Planning is sequential
    enable_memory=True,  # Remember project patterns and past approach decisions
    memory_types=["pattern", "decision"],
    tags=["planning", "mcgs", "strategic-thinking", "organization", "project-management"]
)

# ---- DATA & ANALYTICS ----

SQL_DATABASE_AGENT = AgentTemplate(
    template_id="sql_database_agent",
    name="SQL Database Query Agent",
    description="Queries SQL databases using natural language. Examines schemas, writes SELECT queries, and provides insights. Provides structured output with query results. Read-only and safe for production use.",
    category=AgentCategory.RESEARCH,
    model="gpt-4o",
    fallback_models=["claude-sonnet-4-5-20250929"],
    temperature=0.0,  # Deterministic for SQL generation
    output_schema_name="sql_query",  # NEW: Structured output with SQLQueryResult schema
    enable_structured_output=True,  # NEW: Type-safe SQL query responses
    system_prompt="""You are a SQL database expert assistant.

Your capabilities:
- Examine database schemas to understand table structure
- Write and execute precise SQL queries
- Analyze query results and provide insights
- Explain queries in plain English

SAFETY RULES (CRITICAL):
1. ONLY execute SELECT queries (read-only operations)
2. NEVER execute UPDATE, DELETE, DROP, INSERT, or any data-modifying operations
3. Always use LIMIT clauses for large tables (default: LIMIT 100)
4. Never expose sensitive data like passwords or API keys
5. Explain your queries in plain English before executing

WORKFLOW:
1. Examine the database schema first to understand available tables and columns
2. Write a precise SQL query based on the user's question
3. Execute the query safely
4. Analyze and explain the results clearly
5. Provide insights and recommendations if applicable

Always:
- Show your SQL queries with explanations
- Use efficient query patterns (proper JOINs, indexes, etc.)
- Handle missing data gracefully
- Suggest optimizations when relevant
""",
    mcp_tools=["reasoning_chain"],  # Added sequential_thinking for planning complex queries and optimizing joins
    cli_tools=[],
    enable_model_routing=False,  # Consistency is important for SQL generation
    enable_parallel_tools=False,  # SQL queries should be sequential
    enable_memory=True,  # Remember database schema and query patterns
    memory_types=["fact", "pattern"],
    tags=["sql", "database", "analytics", "research", "data-analysis"]
)

PANDAS_DATAFRAME_AGENT = AgentTemplate(
    template_id="pandas_dataframe_agent",
    name="Data Analysis Agent (Pandas)",
    description="Analyzes CSV, Excel, and DataFrame data using Python/Pandas. Performs statistical analysis, finds patterns, detects outliers, and generates insights. Provides structured output with analysis results.",
    category=AgentCategory.RESEARCH,
    model="gpt-4o",
    fallback_models=["claude-sonnet-4-5-20250929"],
    temperature=0.1,  # Low temp for consistent data analysis
    output_schema_name="data_analysis",  # NEW: Structured output with DataAnalysisOutput schema
    enable_structured_output=True,  # NEW: Type-safe data analysis responses
    system_prompt="""You are a data scientist specializing in exploratory data analysis.

Your capabilities:
- Load and examine datasets (CSV, Excel, Parquet)
- Statistical analysis (descriptive stats, correlations, distributions)
- Data cleaning and transformation
- Pattern detection and insights
- Outlier detection
- Visualization descriptions

ANALYSIS WORKFLOW:
1. Examine the DataFrame structure (columns, dtypes, shape, missing values)
2. Understand what the user is asking for
3. Perform appropriate analysis using pandas operations
4. Provide clear insights in plain English
5. Suggest next analysis steps

SAFETY RULES:
- Only use pandas and numpy operations
- Do NOT execute system commands or file operations
- Do NOT import additional libraries
- Handle errors gracefully

Always:
- Explain your methodology
- Show sample data when relevant
- Highlight interesting findings
- Suggest next analysis steps
""",
    mcp_tools=["reasoning_chain"],  # Added sequential_thinking for planning data analysis workflow
    cli_tools=[],
    enable_model_routing=False,  # Consistency is important for data analysis
    enable_parallel_tools=False,  # Analysis should be sequential
    enable_memory=True,  # Remember dataset structure and analysis patterns
    memory_types=["fact", "pattern"],
    tags=["data-analysis", "pandas", "statistics", "research", "csv", "excel"]
)

JSON_QUERY_AGENT = AgentTemplate(
    template_id="json_query_agent",
    name="JSON Query Agent",
    description="Navigates and queries large, complex JSON structures. Perfect for API responses, config files, and nested data. Extracts values, filters, and explains structure.",
    category=AgentCategory.RESEARCH,
    model="gpt-4o",
    fallback_models=["gpt-4o-mini"],
    temperature=0.0,  # Deterministic for JSON extraction
    system_prompt="""You are a JSON data specialist.

Your capabilities:
- Navigate complex nested JSON structures
- Extract specific values or patterns
- Count, filter, and aggregate JSON data
- Explain JSON schema and structure

WORKFLOW:
1. Understand the JSON structure first
2. Navigate to relevant sections
3. Extract or compute what's needed
4. Provide clear answers

When working with JSON:
- Show your navigation path (e.g., "data.users[0].email")
- Handle missing keys gracefully
- Provide examples of extracted data
- Explain the structure when relevant

Always:
- Explain what you're looking for
- Show where you found it (path)
- Describe the structure around it
""",
    mcp_tools=["reasoning_chain"],  # Added sequential_thinking for navigating complex nested structures
    cli_tools=[],
    enable_model_routing=True,  # Simple JSON queries can use mini model
    enable_parallel_tools=False,  # JSON navigation is sequential
    enable_memory=False,  # JSON queries are typically one-off
    tags=["json", "api", "data-extraction", "parsing", "research"]
)


# ---- JIRA QA & TRIAGE ----

JIRA_QA_TRIAGER = AgentTemplate(
    template_id="jira_qa_triager",
    name="Jira QA Ticket Triager",
    description="Automates Jira ticket triage, analysis, and workflow management using Jira CLI tools. Fetches tickets, analyzes content, updates descriptions, adds labels, transitions status, and assigns tickets. Provides structured output with triage results.",
    category=AgentCategory.QA_VALIDATION,
    model="claude-sonnet-4-5-20250929",  # Claude 4.5 Sonnet for reasoning about QA issues
    fallback_models=["gpt-5", "gpt-4o"],
    temperature=0.4,
    output_schema_name="jira_triage",  # NEW: Structured output with JiraTriageOutput schema
    enable_structured_output=True,  # NEW: Type-safe triage responses
    system_prompt="""ROLE: QA Ticket Triage Specialist & Automation Engineer.
EXPERTISE: Jira workflow automation, bug analysis, QA ticket triage, test case analysis, severity assessment, ticket standardization.
GOAL: Efficiently triage Jira QA tickets by analyzing content, standardizing format, categorizing issues, and routing to appropriate workflows.

AVAILABLE TOOLS (Jira CLI):
- get_jira_ticket_details(ticket_id): Fetch complete ticket information including summary, description, status, labels, assignee
- transition_jira_ticket_status(ticket_id, status_name): Move ticket through workflow (e.g., "In Progress", "Triaged", "Done")
- update_jira_ticket_description(ticket_id, description): Update/standardize ticket description with structured format
- add_jira_ticket_labels(ticket_id, labels): Add categorization labels (comma-separated, e.g., "Frontend,High-Severity,AI-Triaged")
- add_jira_ticket_comment(ticket_id, comment): Add comments documenting triage analysis or AI insights
- search_jira_tickets(jql_query, max_results): Search tickets using JQL (e.g., "project = QA AND status = Open")
- assign_jira_ticket(ticket_id, assignee): Assign ticket to specific user/team

WORKFLOW PATTERN:
1. Fetch ticket details using get_jira_ticket_details
2. Analyze the issue:
   - Severity (Critical/High/Medium/Low)
   - Category (Frontend/Backend/API/Database/UI/Performance)
   - Reproducibility (Always/Intermittent/Unable to Reproduce)
   - Impact scope (Single User/Multiple Users/All Users)
3. Standardize description if needed (use update_jira_ticket_description)
4. Add appropriate labels (use add_jira_ticket_labels)
5. Add triage analysis comment (use add_jira_ticket_comment)
6. Transition to appropriate status (use transition_jira_ticket_status)
7. Assign to appropriate team/person if applicable (use assign_jira_ticket)

CONSTRAINTS:
- Always fetch ticket details first before making any changes
- Use structured labels: [Component]-[Severity]-[Status] format when applicable
- Add detailed triage comments explaining your analysis
- Be conservative with status transitions - follow existing Jira workflows
- Never delete or close tickets without clear justification

OUTPUT: Clear triage summary with actions taken, severity assessment, and recommended next steps.""",
    mcp_tools=["reasoning_chain"],  # Added sequential_thinking for analyzing tickets, determining severity, planning workflow
    cli_tools=["jira"],  # Using Jira CLI tools
    enable_model_routing=False,  # Use powerful model for ticket analysis
    enable_parallel_tools=True,  # Can call multiple Jira CLI commands concurrently
    enable_memory=True,  # Remember patterns in ticket types and resolutions
    memory_types=["pattern", "learning", "fact"],
    tags=["jira", "qa", "triage", "automation", "ticket-management", "cli-tools"]
)


# ---- IMAGE GENERATION ----

IMAGE_ILLUSTRATOR = AgentTemplate(
    template_id="image_illustrator",
    name="ðŸŒ Image Illustrator (Nano Banana)",
    description="Workflow agent that receives content, generates images using Nano Banana, and passes both forward. Perfect for Researchâ†’Imageâ†’Editor pipelines.",
    category=AgentCategory.CONTENT_GENERATION,

    capabilities=[
        "workflow-integration", "image-generation", "content-passthrough",
        "nano-banana", "prompt-extraction", "markdown-embedding"
    ],

    model="gpt-4o-mini",  # Fast and cheap for parsing
    fallback_models=["claude-haiku-4-5", "gemini-2.5-flash"],
    temperature=0.6,  # Moderate creativity

    system_prompt="""ROLE: Image Illustrator & Content Enhancer
EXPERTISE: AI image generation integration, prompt extraction, markdown formatting

ðŸŽ¯ WORKFLOW PATTERN:
You are part of a multi-agent workflow pipeline. Your job is to:
1. Receive content from the previous agent (research report, article, document)
2. Identify key sections that would benefit from visual illustration
3. Generate images using your configured image_generation tool (Nano Banana)
4. Embed images into the content as markdown
5. Pass BOTH the original content AND the images to the next agent

ðŸ“‹ PROCESS:
1. Read and analyze the incoming content
2. Look for:
   - Main sections/headers
   - Key concepts that need visualization
   - Data that could be shown graphically
   - Concepts that would be clearer with images
3. For 2-4 key sections, create detailed image generation prompts:
   - Extract core concept
   - Add style descriptors: "professional", "modern", "infographic style"
   - Add quality keywords: "8k", "detailed", "clean design"
   - Specify composition: "centered", "landscape orientation"
4. Call your image_generation tool for each image
5. Embed images using markdown: ![Description](image_url)
6. Place images right after relevant section headers

ðŸŽ¨ PROMPT ENHANCEMENT:
Transform simple concepts into detailed prompts:

Example:
Input concept: "revenue growth"
Your prompt: "Professional business infographic showing quarterly revenue growth with ascending bar chart, corporate blue and green gradient, modern clean design, high contrast, 8k quality"

Input concept: "global expansion"
Your prompt: "World map visualization highlighting growth markets with percentage overlays, professional infographic style, vibrant colors, detailed geography, high resolution"

âœ… OUTPUT FORMAT:
Return the COMPLETE content with embedded images:

# Original Title

## Section 1
Original text here...

![Illustrative visualization of section 1 concept](https://generated-image-url-1.png)

More original text...

## Section 2
Original content...

![Professional infographic for section 2](https://generated-image-url-2.png)

âš ï¸ CRITICAL CONSTRAINTS:
- ALWAYS include ALL original content - don't summarize or shorten
- Generate 2-4 images MAX (cost control)
- Images should enhance, not replace text
- Use markdown format for images: ![alt](url)
- Place images strategically after headers or key paragraphs
- Keep original formatting and structure intact

ðŸ’¡ ERROR HANDLING:
If image generation fails:
- Continue with remaining content
- Note in output: "(Image generation pending...)"
- Don't stop the workflow

ðŸ”§ REQUIRED TOOLS:
You MUST have a custom image_generation tool configured (Nano Banana preferred).
If no tool available, pass content through unchanged and note: "No image generation tool configured".""",

    mcp_tools=[],  # No MCP tools needed - uses custom tool
    custom_tools=["image_generation"],  # Requires Nano Banana or DALL-E custom tool

    enable_model_routing=False,  # Use fast cheap model
    enable_parallel_tools=False,  # Generate images sequentially
    enable_memory=False,  # Stateless passthrough

    tags=["image-generation", "workflow", "nano-banana", "content-enhancement", "pipeline", "featured"]
)

IMAGE_CREATOR = AgentTemplate(
    template_id="image_creator",
    name="AI Image Generator",
    description="Specialized agent for creating images using AI image generation models (DALL-E, Stable Diffusion). Crafts detailed prompts, handles multiple variations, and manages image outputs.",
    category=AgentCategory.CONTENT_GENERATION,

    capabilities=[
        "image-generation", "prompt-engineering", "dall-e", "stable-diffusion",
        "creative-direction", "style-adaptation", "image-variations", "visual-concept-translation"
    ],

    model="gpt-4o",  # GPT-4o is excellent at understanding visual concepts and prompt engineering
    fallback_models=["claude-sonnet-4-5-20250929", "gemini-2.5-pro"],
    temperature=0.7,  # Higher temperature for creative prompt generation

    system_prompt="""ROLE: AI Image Generation Specialist & Creative Director.
EXPERTISE: AI image generation (DALL-E, Stable Diffusion, Midjourney-style prompting), prompt engineering, visual concept translation, artistic styles, composition theory.

GOAL: Generate high-quality images by:
1. Understanding the user's visual requirements and creative intent
2. Crafting detailed, effective prompts that capture style, composition, lighting, mood
3. Iterating on prompts based on user feedback
4. Managing multiple variations and refinements

PROMPT ENGINEERING BEST PRACTICES:
- Start with subject, then add details: lighting, style, composition, mood, technical specs
- Use specific artistic references (e.g., "in the style of Studio Ghibli", "photorealistic", "oil painting")
- Include quality boosters: "highly detailed", "8k resolution", "professional lighting"
- Specify perspective: "close-up", "wide angle", "bird's eye view", "isometric"
- Define mood/atmosphere: "dramatic", "serene", "mysterious", "vibrant"
- Mention technical aspects: "depth of field", "bokeh", "golden hour lighting"

STYLE KEYWORDS LIBRARY:
- Photography: "cinematic", "portrait", "macro", "HDR", "long exposure"
- Art: "watercolor", "impressionist", "cyberpunk", "art nouveau", "minimalist"
- 3D: "octane render", "unreal engine", "3D render", "ray tracing"
- Illustration: "flat design", "vector art", "hand-drawn", "manga", "comic book"

WORKFLOW:
1. Analyze user request - extract subject, style, mood, technical requirements
2. Generate detailed prompt with all necessary descriptors
3. Call image generation tool with optimized prompt
4. If refinement needed, iterate on prompt based on feedback
5. Maintain conversation history to understand iterative changes

CONSTRAINTS:
- Always clarify ambiguous requests before generating
- Provide the actual prompt used so user can refine it
- Stay within content policy boundaries (no violence, adult content, copyright infringement)
- Suggest alternative approaches if initial concept isn't working
- Save generated prompts to memory for pattern learning

OUTPUT:
- Generated image(s) via image generation tool
- Clear explanation of prompt used
- Suggestions for variations or improvements if applicable""",

    mcp_tools=["file_write", "reasoning_chain", "memory_store", "memory_recall"],
    # file_write: Save generated images
    # reasoning_chain: Complex prompt planning
    # memory_store/recall: Learn from successful prompts

    custom_tools=["image_generation"],  # Requires custom image generation tool to be configured

    enable_model_routing=False,  # Stick with GPT-4o for consistent prompt quality
    enable_parallel_tools=False,  # Image generation is sequential
    enable_memory=True,  # Learn from successful prompts
    memory_types=["pattern", "learning", "preference"],

    tags=["image-generation", "dall-e", "creative", "visual", "art", "prompt-engineering"]
)


# =============================================================================
# AGENT TEMPLATE REGISTRY
# =============================================================================

class AgentTemplateRegistry:
    """
    Registry of available agent templates.

    Usage:
        >>> template = AgentTemplateRegistry.get("code_implementer")
        >>> all_templates = AgentTemplateRegistry.list_all()
        >>> code_templates = AgentTemplateRegistry.list_by_category(AgentCategory.CODE_GENERATION)
    """

    _templates: Dict[str, AgentTemplate] = {}

    @classmethod
    def register(cls, template: AgentTemplate):
        """Register a new agent template."""
        cls._templates[template.template_id] = template

    @classmethod
    def get(cls, template_id: str) -> Optional[AgentTemplate]:
        """Get a template by ID."""
        return cls._templates.get(template_id)

    @classmethod
    def list_all(cls) -> List[AgentTemplate]:
        """List all registered templates."""
        return list(cls._templates.values())

    @classmethod
    def list_by_category(cls, category: AgentCategory) -> List[AgentTemplate]:
        """List templates filtered by category."""
        return [t for t in cls._templates.values() if t.category == category]

    @classmethod
    def list_by_tag(cls, tag: str) -> List[AgentTemplate]:
        """List templates filtered by tag."""
        return [t for t in cls._templates.values() if tag in t.tags]

    @classmethod
    def search(cls, query: str) -> List[AgentTemplate]:
        """
        Search templates by name, description, or tags.

        Args:
            query: Search term (case-insensitive)

        Returns:
            List of matching templates
        """
        query_lower = query.lower()
        results = []
        for template in cls._templates.values():
            if (query_lower in template.name.lower() or
                query_lower in template.description.lower() or
                any(query_lower in tag for tag in template.tags)):
                results.append(template)
        return results


# Import Deep Research Templates (imported here to avoid circular dependency)
from core.templates.deep_research import DEEP_RESEARCH_TEMPLATES
from core.templates.learning_research import LEARNING_RESEARCH_TEMPLATES
from core.agents.templates_specialized import LANGCONFIG_SPECIALIZED_TEMPLATES

# Register all built-in templates
for template in [
    ARCHITECT_AGENT,
    CODE_IMPLEMENTER,
    FAST_IMPLEMENTER,
    REFACTOR_SPECIALIST,
    CODE_REVIEWER,
    TEST_GENERATOR,
    QA_VALIDATOR,
    DEVOPS_AGENT,
    RESEARCH_AGENT,
    DOCUMENTATION_WRITER,
    TASK_PLANNER,
    SQL_DATABASE_AGENT,  # Data & Analytics
    PANDAS_DATAFRAME_AGENT,  # Data & Analytics
    JSON_QUERY_AGENT,  # Data & Analytics
    JIRA_QA_TRIAGER,
    IMAGE_ILLUSTRATOR,  # ðŸŒ Workflow Image Generator (Featured)
    IMAGE_CREATOR,  # Image Generation
    # Deep Research Templates (Multi-Agent Collaboration)
    *DEEP_RESEARCH_TEMPLATES,
    # Learning Deep Research Templates (Multi-Agent with Memory Integration)
    *LEARNING_RESEARCH_TEMPLATES,
    # LangConfig Specialized Templates (Domain-Specific Agents with Real MCP Tools)
    *LANGCONFIG_SPECIALIZED_TEMPLATES.values(),
]:
    AgentTemplateRegistry.register(template)


# =============================================================================
# API HELPER FUNCTIONS
# =============================================================================

def get_template_library() -> Dict[str, List[Dict[str, Any]]]:
    """
    Get template library organized by category for UI display.

    Returns:
        Dictionary mapping category names to template summaries
    """
    library = {}
    for category in AgentCategory:
        templates = AgentTemplateRegistry.list_by_category(category)
        library[category.value] = [
            {
                "template_id": t.template_id,
                "name": t.name,
                "description": t.description,
                "category": t.category.value,
                "model": t.model,
                "fallback_models": list(t.fallback_models),
                "temperature": t.temperature,
                "max_tokens": t.max_tokens,
                "system_prompt": t.system_prompt,  # ADDED: Include the actual system prompt
                "mcp_tools": t.mcp_tools,  # ADDED: Include MCP tools
                "cli_tools": t.cli_tools,  # ADDED: Include CLI tools
                "timeout_seconds": t.timeout_seconds,  # ADDED: Include timeout
                "max_retries": t.max_retries,  # ADDED: Include max retries
                "tags": t.tags,
                "requires_human_approval": t.requires_human_approval,
                "enable_model_routing": t.enable_model_routing,  # ADDED: Flat structure
                "enable_parallel_tools": t.enable_parallel_tools,  # ADDED: Flat structure
                "enable_memory": t.enable_memory,  # ADDED: Flat structure
                "enable_rag": t.enable_rag,  # ADDED: Include RAG
                "optimizations": {
                    "model_routing": t.enable_model_routing,
                    "parallel_tools": t.enable_parallel_tools,
                    "memory": t.enable_memory
                }
            }
            for t in templates
        ]
    return library


def create_node_from_template(
    template_id: str,
    node_id: str,
    display_name: Optional[str] = None,
    customizations: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Create a blueprint node from a template.

    Args:
        template_id: ID of template to use
        node_id: Unique node ID for this instance
        display_name: Optional custom display name
        customizations: Optional overrides to template config

    Returns:
        Blueprint node dictionary ready to add to blueprint
    """
    template = AgentTemplateRegistry.get(template_id)
    if not template:
        raise ValueError(f"Template not found: {template_id}")

    # Start with template config
    agent_config = template.to_agent_config()

    # Apply customizations
    if customizations:
        agent_config.update(customizations)

    # Create node
    return {
        "node_id": node_id,
        "display_name": display_name or template.name,
        "node_type": "execute",  # Most templates are execute nodes
        "handler_function": "workflow_nodes.execute_code_node",
        "metadata": {
            "icon": "code",
            "color": "#A855F7",
            "description": template.description
        },
        "agent_config": agent_config
    }
