# Copyright (c) 2025 Cade Russell (Ghost Peony)
#
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.

"""initial_schema

Revision ID: dbbae99c3f1c
Revises: 
Create Date: 2025-12-01 01:07:22.720877

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'dbbae99c3f1c'
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('store_migrations')
    op.drop_index(op.f('checkpoints_thread_id_idx'), table_name='checkpoints')
    op.drop_table('checkpoints')
    op.drop_index(op.f('checkpoint_blobs_thread_id_idx'), table_name='checkpoint_blobs')
    op.drop_table('checkpoint_blobs')
    op.drop_table('vector_documents')
    op.drop_index(op.f('context_documents_embeddings_idx_1'), table_name='data_context_documents_embeddings')
    op.drop_index(op.f('data_context_documents_embeddings_embedding_idx'), table_name='data_context_documents_embeddings', postgresql_ops={'embedding': 'vector_cosine_ops'}, postgresql_with={'m': '16', 'ef_construction': '64'}, postgresql_using='hnsw')
    op.drop_table('data_context_documents_embeddings')
    op.drop_table('checkpoint_migrations')
    op.drop_index(op.f('checkpoint_writes_thread_id_idx'), table_name='checkpoint_writes')
    op.drop_table('checkpoint_writes')
    op.drop_index(op.f('idx_store_expires_at'), table_name='store', postgresql_where='(expires_at IS NOT NULL)')
    op.drop_index(op.f('store_prefix_idx'), table_name='store', postgresql_ops={'prefix': 'text_pattern_ops'})
    op.drop_table('store')
    op.alter_column('agent_exports', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=sa.text('now()'),
               existing_nullable=False)
    op.add_column('audit_logs', sa.Column('additional_context', sa.JSON(), nullable=True))
    op.drop_column('audit_logs', 'extra_metadata')
    op.alter_column('chat_sessions', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=sa.text('now()'),
               existing_nullable=False)
    op.alter_column('chat_sessions', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=sa.text('now()'),
               existing_nullable=False)
    op.create_index(op.f('ix_chat_sessions_agent_id'), 'chat_sessions', ['agent_id'], unique=False)
    op.add_column('deep_agent_templates', sa.Column('lock_version', sa.Integer(), server_default='1', nullable=False))
    op.alter_column('deep_agent_templates', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=sa.text('now()'),
               existing_nullable=False)
    op.alter_column('deep_agent_templates', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=sa.text('now()'),
               existing_nullable=False)
    op.alter_column('execution_events', 'timestamp',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.alter_column('tasks', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=None,
               existing_nullable=True)
    op.drop_constraint(op.f('tasks_project_id_fkey'), 'tasks', type_='foreignkey')
    op.create_foreign_key(None, 'tasks', 'projects', ['project_id'], ['id'])
    op.add_column('workflow_profiles', sa.Column('export_status', sa.String(length=50), nullable=True))
    op.add_column('workflow_profiles', sa.Column('export_error', sa.Text(), nullable=True))
    op.add_column('workflow_profiles', sa.Column('last_export_at', sa.DateTime(timezone=True), nullable=True))
    op.add_column('workflow_profiles', sa.Column('lock_version', sa.Integer(), server_default='1', nullable=False))
    op.alter_column('workflow_profiles', 'strategy_type',
               existing_type=postgresql.ENUM('default_sequential', 'roman_legion', 'quorum_sensing', 'stigmergy', 'deep_research', 'learning_research', 'supervisor_development', 'supervisor_code_review', 'supervisor_architecture', 'rlm', 'rlm_rag_hybrid', name='workflowstrategy'),
               nullable=True)
    op.create_index(op.f('ix_workflow_profiles_project_id'), 'workflow_profiles', ['project_id'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_workflow_profiles_project_id'), table_name='workflow_profiles')
    op.alter_column('workflow_profiles', 'strategy_type',
               existing_type=postgresql.ENUM('default_sequential', 'roman_legion', 'quorum_sensing', 'stigmergy', 'deep_research', 'learning_research', 'supervisor_development', 'supervisor_code_review', 'supervisor_architecture', 'rlm', 'rlm_rag_hybrid', name='workflowstrategy'),
               nullable=False)
    op.drop_column('workflow_profiles', 'lock_version')
    op.drop_column('workflow_profiles', 'last_export_at')
    op.drop_column('workflow_profiles', 'export_error')
    op.drop_column('workflow_profiles', 'export_status')
    op.drop_constraint(None, 'tasks', type_='foreignkey')
    op.create_foreign_key(op.f('tasks_project_id_fkey'), 'tasks', 'projects', ['project_id'], ['id'], ondelete='CASCADE')
    op.alter_column('tasks', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=sa.text('now()'),
               existing_nullable=True)
    op.alter_column('execution_events', 'timestamp',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.alter_column('deep_agent_templates', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=None,
               existing_nullable=False)
    op.alter_column('deep_agent_templates', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=None,
               existing_nullable=False)
    op.drop_column('deep_agent_templates', 'lock_version')
    op.drop_index(op.f('ix_chat_sessions_agent_id'), table_name='chat_sessions')
    op.alter_column('chat_sessions', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=None,
               existing_nullable=False)
    op.alter_column('chat_sessions', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=None,
               existing_nullable=False)
    op.add_column('audit_logs', sa.Column('extra_metadata', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.drop_column('audit_logs', 'additional_context')
    op.alter_column('agent_exports', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=None,
               existing_nullable=False)
    op.create_table('store',
    sa.Column('prefix', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('key', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('value', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.Column('expires_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('ttl_minutes', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('prefix', 'key', name=op.f('store_pkey'))
    )
    op.create_index(op.f('store_prefix_idx'), 'store', ['prefix'], unique=False, postgresql_ops={'prefix': 'text_pattern_ops'})
    op.create_index(op.f('idx_store_expires_at'), 'store', ['expires_at'], unique=False, postgresql_where='(expires_at IS NOT NULL)')
    op.create_table('checkpoint_writes',
    sa.Column('thread_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('checkpoint_ns', sa.TEXT(), server_default=sa.text("''::text"), autoincrement=False, nullable=False),
    sa.Column('checkpoint_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('task_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('idx', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('channel', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('type', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('blob', postgresql.BYTEA(), autoincrement=False, nullable=False),
    sa.Column('task_path', sa.TEXT(), server_default=sa.text("''::text"), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('thread_id', 'checkpoint_ns', 'checkpoint_id', 'task_id', 'idx', name=op.f('checkpoint_writes_pkey'))
    )
    op.create_index(op.f('checkpoint_writes_thread_id_idx'), 'checkpoint_writes', ['thread_id'], unique=False)
    op.create_table('checkpoint_migrations',
    sa.Column('v', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('v', name=op.f('checkpoint_migrations_pkey'))
    )
    op.create_table('data_context_documents_embeddings',
    sa.Column('id', sa.BIGINT(), autoincrement=True, nullable=False),
    sa.Column('text', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('metadata_', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('node_id', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('embedding', sa.NullType(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('data_context_documents_embeddings_pkey'))
    )
    op.create_index(op.f('data_context_documents_embeddings_embedding_idx'), 'data_context_documents_embeddings', ['embedding'], unique=False, postgresql_ops={'embedding': 'vector_cosine_ops'}, postgresql_with={'m': '16', 'ef_construction': '64'}, postgresql_using='hnsw')
    op.create_index(op.f('context_documents_embeddings_idx_1'), 'data_context_documents_embeddings', [sa.literal_column("(metadata_ ->> 'ref_doc_id'::text)")], unique=False)
    op.create_table('vector_documents',
    sa.Column('id', sa.UUID(), server_default=sa.text('uuid_generate_v4()'), autoincrement=False, nullable=False),
    sa.Column('content', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), autoincrement=False, nullable=True),
    sa.Column('embedding', sa.NullType(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('vector_documents_pkey'))
    )
    op.create_table('checkpoint_blobs',
    sa.Column('thread_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('checkpoint_ns', sa.TEXT(), server_default=sa.text("''::text"), autoincrement=False, nullable=False),
    sa.Column('channel', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('version', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('type', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('blob', postgresql.BYTEA(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('thread_id', 'checkpoint_ns', 'channel', 'version', name=op.f('checkpoint_blobs_pkey'))
    )
    op.create_index(op.f('checkpoint_blobs_thread_id_idx'), 'checkpoint_blobs', ['thread_id'], unique=False)
    op.create_table('checkpoints',
    sa.Column('thread_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('checkpoint_ns', sa.TEXT(), server_default=sa.text("''::text"), autoincrement=False, nullable=False),
    sa.Column('checkpoint_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('parent_checkpoint_id', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('type', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('checkpoint', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('thread_id', 'checkpoint_ns', 'checkpoint_id', name=op.f('checkpoints_pkey'))
    )
    op.create_index(op.f('checkpoints_thread_id_idx'), 'checkpoints', ['thread_id'], unique=False)
    op.create_table('store_migrations',
    sa.Column('v', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('v', name=op.f('store_migrations_pkey'))
    )
    # ### end Alembic commands ###
